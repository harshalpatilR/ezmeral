++ id -u
+ myuid=185
++ id -g
+ mygid=0
+ set +e
++ getent passwd 185
+ uidentry=
+ set -e
+ '[' -z '' ']'
+ '[' -w /etc/passwd ']'
+ echo '185:x:185:0:anonymous uid:/opt/spark:/bin/false'
+ '[' -z /opt/java/openjdk ']'
+ SPARK_CLASSPATH=':/opt/spark/jars/*'
+ env
+ grep SPARK_JAVA_OPT_
+ sort -t_ -k4 -n
+ sed 's/[^=]*=\(.*\)/\1/g'
++ command -v readarray
+ '[' readarray ']'
+ readarray -t SPARK_EXECUTOR_JAVA_OPTS
+ '[' -n '' ']'
+ '[' -z ']'
+ '[' -z ']'
+ '[' -n '' ']'
+ '[' -z ']'
+ '[' -z x ']'
+ SPARK_CLASSPATH='/opt/spark/conf::/opt/spark/jars/*'
+ SPARK_CLASSPATH='/opt/spark/conf::/opt/spark/jars/*:/opt/spark/work-dir'
+ case "$1" in
+ shift 1
+ CMD=("$SPARK_HOME/bin/spark-submit" --conf "spark.driver.bindAddress=$SPARK_DRIVER_BIND_ADDRESS" --conf "spark.executorEnv.SPARK_DRIVER_POD_IP=$SPARK_DRIVER_BIND_ADDRESS" --deploy-mode client "$@")
+ exec /usr/bin/tini -s -- /opt/spark/bin/spark-submit --conf spark.driver.bindAddress=10.224.118.154 --conf spark.executorEnv.SPARK_DRIVER_POD_IP=10.224.118.154 --deploy-mode client --properties-file /opt/spark/conf/spark.properties --class org.apache.spark.deploy.PythonRunner local:///mounts/shared-volume/shared/harshal/readcsv_S3proxy.py
Files local:///mounts/shared-volume/shared/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar from /mounts/shared-volume/shared/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar to /opt/spark/work-dir/spark-sql-kafka-0-10_2.12-3.5.1.jar
Files local:///mounts/shared-volume/shared/jars/kafka-clients-2.6.1.jar from /mounts/shared-volume/shared/jars/kafka-clients-2.6.1.jar to /opt/spark/work-dir/kafka-clients-2.6.1.jar
Files local:///mounts/shared-volume/shared/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar from /mounts/shared-volume/shared/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar to /opt/spark/work-dir/spark-token-provider-kafka-0-10_2.12-3.5.1.jar
Files local:///mounts/shared-volume/shared/jars/commons-pool2-2.11.1.jar from /mounts/shared-volume/shared/jars/commons-pool2-2.11.1.jar to /opt/spark/work-dir/commons-pool2-2.11.1.jar
Files local:///mounts/shared-volume/shared/jars/iceberg-spark-runtime-3.5_2.12-1.6.0.jar from /mounts/shared-volume/shared/jars/iceberg-spark-runtime-3.5_2.12-1.6.0.jar to /opt/spark/work-dir/iceberg-spark-runtime-3.5_2.12-1.6.0.jar
24/09/13 04:53:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/13 04:53:47 INFO SparkContext: Running Spark version 3.5.1
24/09/13 04:53:47 INFO SparkContext: OS info Linux, 4.18.0-477.15.1.el8_8.x86_64, amd64
24/09/13 04:53:47 INFO SparkContext: Java version 17.0.11
24/09/13 04:53:47 INFO ResourceUtils: ==============================================================
24/09/13 04:53:47 INFO ResourceUtils: No custom resources configured for spark.driver.
24/09/13 04:53:47 INFO ResourceUtils: ==============================================================
24/09/13 04:53:47 INFO SparkContext: Submitted application: ReadCSVFromS3Proxy
24/09/13 04:53:47 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/09/13 04:53:48 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
24/09/13 04:53:48 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/09/13 04:53:48 INFO SecurityManager: Changing view acls to: 185,harshal
24/09/13 04:53:48 INFO SecurityManager: Changing modify acls to: 185,harshal
24/09/13 04:53:48 INFO SecurityManager: Changing view acls groups to: 
24/09/13 04:53:48 INFO SecurityManager: Changing modify acls groups to: 
24/09/13 04:53:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: 185, harshal; groups with view permissions: EMPTY; users with modify permissions: 185, harshal; groups with modify permissions: EMPTY
24/09/13 04:53:48 INFO Utils: Successfully started service 'sparkDriver' on port 7078.
24/09/13 04:53:48 INFO SparkEnv: Registering MapOutputTracker
24/09/13 04:53:48 INFO SparkEnv: Registering BlockManagerMaster
24/09/13 04:53:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/09/13 04:53:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/09/13 04:53:48 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/09/13 04:53:48 INFO DiskBlockManager: Created local directory at /var/data/spark-8a34b8fd-24a3-4fc0-9d7a-68e747f7104d/blockmgr-23fcd441-3a0b-4059-a0c7-d643c2127c00
24/09/13 04:53:48 INFO MemoryStore: MemoryStore started with capacity 2.1 GiB
24/09/13 04:53:48 INFO SparkEnv: Registering OutputCommitCoordinator
24/09/13 04:53:48 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/09/13 04:53:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/09/13 04:53:48 INFO SparkContext: Added JAR local:/mounts/shared-volume/shared/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar at file:/mounts/shared-volume/shared/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar with timestamp 1726203227903
24/09/13 04:53:48 INFO SparkContext: Added JAR local:/mounts/shared-volume/shared/jars/kafka-clients-2.6.1.jar at file:/mounts/shared-volume/shared/jars/kafka-clients-2.6.1.jar with timestamp 1726203227903
24/09/13 04:53:48 INFO SparkContext: Added JAR local:/mounts/shared-volume/shared/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar at file:/mounts/shared-volume/shared/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar with timestamp 1726203227903
24/09/13 04:53:48 INFO SparkContext: Added JAR local:/mounts/shared-volume/shared/jars/commons-pool2-2.11.1.jar at file:/mounts/shared-volume/shared/jars/commons-pool2-2.11.1.jar with timestamp 1726203227903
24/09/13 04:53:48 INFO SparkContext: Added JAR local:/mounts/shared-volume/shared/jars/iceberg-spark-runtime-3.5_2.12-1.6.0.jar at file:/mounts/shared-volume/shared/jars/iceberg-spark-runtime-3.5_2.12-1.6.0.jar with timestamp 1726203227903
24/09/13 04:53:48 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file
24/09/13 04:53:50 INFO ExecutorPodsAllocator: Going to request 1 executors from Kubernetes for ResourceProfile Id: 0, target: 1, known: 0, sharedSlotFromPendingPods: 2147483647.
24/09/13 04:53:50 INFO ExecutorPodsAllocator: Found 0 reusable PVCs from 0 PVCs
24/09/13 04:53:50 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script
24/09/13 04:53:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7079.
24/09/13 04:53:50 INFO NettyBlockTransferService: Server created on hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc 10.224.118.154:7079
24/09/13 04:53:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/13 04:53:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc, 7079, None)
24/09/13 04:53:50 INFO BlockManagerMasterEndpoint: Registering block manager hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc:7079 with 2.1 GiB RAM, BlockManagerId(driver, hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc, 7079, None)
24/09/13 04:53:50 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc, 7079, None)
24/09/13 04:53:50 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc, 7079, None)
24/09/13 04:53:51 INFO SingleEventLogFileWriter: Logging events to file:/opt/mapr/spark/sparkhs-eventlog-storage/spark-3ea4cc2488c448d6ad04ec970d56138d.inprogress
24/09/13 04:54:01 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: No executor found for 10.224.118.129:43598
24/09/13 04:54:01 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.224.118.129:43602) with ID 1,  ResourceProfileId 0
24/09/13 04:54:01 INFO KubernetesClusterSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
24/09/13 04:54:01 INFO BlockManagerMasterEndpoint: Registering block manager 10.224.118.129:44791 with 2.1 GiB RAM, BlockManagerId(1, 10.224.118.129, 44791, None)
24/09/13 04:54:01 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
24/09/13 04:54:01 INFO SharedState: Warehouse path is 'file:/opt/spark/work-dir/spark-warehouse'.
24/09/13 04:54:02 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
24/09/13 04:54:02 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
24/09/13 04:54:02 INFO MetricsSystemImpl: s3a-file-system metrics system started
24/09/13 04:54:03 WARN AmazonHttpClient: SSL Certificate checking for endpoints has been explicitly disabled.
24/09/13 04:54:04 INFO InMemoryFileIndex: It took 475 ms to list leaf files for 1 paths.
24/09/13 04:54:05 INFO InMemoryFileIndex: It took 385 ms to list leaf files for 1 paths.
24/09/13 04:54:07 INFO FileSourceStrategy: Pushed Filters: 
24/09/13 04:54:07 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
24/09/13 04:54:08 INFO CodeGenerator: Code generated in 218.182036 ms
24/09/13 04:54:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 221.6 KiB, free 2.1 GiB)
24/09/13 04:54:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.3 KiB, free 2.1 GiB)
24/09/13 04:54:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc:7079 (size: 38.3 KiB, free: 2.1 GiB)
24/09/13 04:54:08 INFO SparkContext: Created broadcast 0 from csv at <unknown>:0
24/09/13 04:54:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
24/09/13 04:54:08 INFO SparkContext: Starting job: csv at <unknown>:0
24/09/13 04:54:08 INFO DAGScheduler: Got job 0 (csv at <unknown>:0) with 1 output partitions
24/09/13 04:54:08 INFO DAGScheduler: Final stage: ResultStage 0 (csv at <unknown>:0)
24/09/13 04:54:08 INFO DAGScheduler: Parents of final stage: List()
24/09/13 04:54:08 INFO DAGScheduler: Missing parents: List()
24/09/13 04:54:08 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0), which has no missing parents
24/09/13 04:54:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 13.5 KiB, free 2.1 GiB)
24/09/13 04:54:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 2.1 GiB)
24/09/13 04:54:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc:7079 (size: 6.4 KiB, free: 2.1 GiB)
24/09/13 04:54:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
24/09/13 04:54:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 04:54:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/09/13 04:54:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.224.118.129, executor 1, partition 0, PROCESS_LOCAL, 8788 bytes) 
24/09/13 04:54:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.224.118.129:44791 (size: 6.4 KiB, free: 2.1 GiB)
24/09/13 04:54:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.224.118.129:44791 (size: 38.3 KiB, free: 2.1 GiB)
24/09/13 04:54:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 3559 ms on 10.224.118.129 (executor 1) (1/1)
24/09/13 04:54:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/09/13 04:54:12 INFO DAGScheduler: ResultStage 0 (csv at <unknown>:0) finished in 3.691 s
24/09/13 04:54:12 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 04:54:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/09/13 04:54:12 INFO DAGScheduler: Job 0 finished: csv at <unknown>:0, took 3.772990 s
24/09/13 04:54:12 INFO CodeGenerator: Code generated in 7.516082 ms
24/09/13 04:54:12 INFO FileSourceStrategy: Pushed Filters: 
24/09/13 04:54:12 INFO FileSourceStrategy: Post-Scan Filters: 
24/09/13 04:54:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 221.6 KiB, free 2.1 GiB)
24/09/13 04:54:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 38.3 KiB, free 2.1 GiB)
24/09/13 04:54:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc:7079 (size: 38.3 KiB, free: 2.1 GiB)
24/09/13 04:54:12 INFO SparkContext: Created broadcast 2 from csv at <unknown>:0
24/09/13 04:54:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
24/09/13 04:54:12 INFO SparkContext: Starting job: csv at <unknown>:0
24/09/13 04:54:12 INFO DAGScheduler: Got job 1 (csv at <unknown>:0) with 1 output partitions
24/09/13 04:54:12 INFO DAGScheduler: Final stage: ResultStage 1 (csv at <unknown>:0)
24/09/13 04:54:12 INFO DAGScheduler: Parents of final stage: List()
24/09/13 04:54:12 INFO DAGScheduler: Missing parents: List()
24/09/13 04:54:12 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at <unknown>:0), which has no missing parents
24/09/13 04:54:12 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 32.2 KiB, free 2.1 GiB)
24/09/13 04:54:12 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 2.1 GiB)
24/09/13 04:54:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc:7079 (size: 14.7 KiB, free: 2.1 GiB)
24/09/13 04:54:12 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
24/09/13 04:54:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 04:54:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/09/13 04:54:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.224.118.129, executor 1, partition 0, PROCESS_LOCAL, 8788 bytes) 
24/09/13 04:54:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.224.118.129:44791 (size: 14.7 KiB, free: 2.1 GiB)
24/09/13 04:54:14 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.224.118.129:44791 (size: 38.3 KiB, free: 2.1 GiB)
24/09/13 04:54:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2765 ms on 10.224.118.129 (executor 1) (1/1)
24/09/13 04:54:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/09/13 04:54:15 INFO DAGScheduler: ResultStage 1 (csv at <unknown>:0) finished in 2.836 s
24/09/13 04:54:15 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 04:54:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/09/13 04:54:15 INFO DAGScheduler: Job 1 finished: csv at <unknown>:0, took 2.840011 s
24/09/13 04:54:15 INFO FileSourceStrategy: Pushed Filters: 
24/09/13 04:54:15 INFO FileSourceStrategy: Post-Scan Filters: 
24/09/13 04:54:15 INFO CodeGenerator: Code generated in 69.949012 ms
24/09/13 04:54:15 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 221.6 KiB, free 2.1 GiB)
24/09/13 04:54:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 38.3 KiB, free 2.1 GiB)
24/09/13 04:54:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc:7079 (size: 38.3 KiB, free: 2.1 GiB)
24/09/13 04:54:15 INFO SparkContext: Created broadcast 4 from showString at <unknown>:0
24/09/13 04:54:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
24/09/13 04:54:15 INFO SparkContext: Starting job: showString at <unknown>:0
24/09/13 04:54:15 INFO DAGScheduler: Got job 2 (showString at <unknown>:0) with 1 output partitions
24/09/13 04:54:15 INFO DAGScheduler: Final stage: ResultStage 2 (showString at <unknown>:0)
24/09/13 04:54:15 INFO DAGScheduler: Parents of final stage: List()
24/09/13 04:54:15 INFO DAGScheduler: Missing parents: List()
24/09/13 04:54:15 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at showString at <unknown>:0), which has no missing parents
24/09/13 04:54:15 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.224.118.129:44791 in memory (size: 14.7 KiB, free: 2.1 GiB)
24/09/13 04:54:15 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 18.4 KiB, free 2.1 GiB)
24/09/13 04:54:15 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 2.1 GiB)
24/09/13 04:54:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc:7079 (size: 8.0 KiB, free: 2.1 GiB)
24/09/13 04:54:15 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
24/09/13 04:54:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 04:54:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/09/13 04:54:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (10.224.118.129, executor 1, partition 0, PROCESS_LOCAL, 8788 bytes) 
24/09/13 04:54:15 INFO BlockManagerInfo: Removed broadcast_3_piece0 on hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc:7079 in memory (size: 14.7 KiB, free: 2.1 GiB)
24/09/13 04:54:15 INFO BlockManagerInfo: Removed broadcast_2_piece0 on hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc:7079 in memory (size: 38.3 KiB, free: 2.1 GiB)
24/09/13 04:54:15 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.224.118.129:44791 in memory (size: 38.3 KiB, free: 2.1 GiB)
24/09/13 04:54:15 INFO BlockManagerInfo: Removed broadcast_0_piece0 on hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc:7079 in memory (size: 38.3 KiB, free: 2.1 GiB)
24/09/13 04:54:15 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.224.118.129:44791 (size: 8.0 KiB, free: 2.1 GiB)
24/09/13 04:54:15 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.224.118.129:44791 in memory (size: 38.3 KiB, free: 2.1 GiB)
24/09/13 04:54:15 INFO BlockManagerInfo: Removed broadcast_1_piece0 on hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc:7079 in memory (size: 6.4 KiB, free: 2.1 GiB)
24/09/13 04:54:15 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.224.118.129:44791 in memory (size: 6.4 KiB, free: 2.1 GiB)
24/09/13 04:54:16 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.224.118.129:44791 (size: 38.3 KiB, free: 2.1 GiB)
24/09/13 04:54:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 603 ms on 10.224.118.129 (executor 1) (1/1)
24/09/13 04:54:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/09/13 04:54:16 INFO DAGScheduler: ResultStage 2 (showString at <unknown>:0) finished in 0.609 s
24/09/13 04:54:16 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 04:54:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/09/13 04:54:16 INFO DAGScheduler: Job 2 finished: showString at <unknown>:0, took 0.671342 s
24/09/13 04:54:16 INFO CodeGenerator: Code generated in 13.228004 ms
+-----------+------------+------------+------------+--------------+-----------+------------+-----------+
|  snp_close|  nyse_close|  djia_close|nikkei_close|hangseng_close| ftse_close|   dax_close| aord_close|
+-----------+------------+------------+------------+--------------+-----------+------------+-----------+
|2098.120117|11112.169922|18067.230469|19623.839844|  27406.179688|6932.799805|11471.410156|5672.100098|
|1413.199951| 8233.910156|13092.160156| 9050.219727|  22110.330078|5867.600098| 7362.850098|4482.299805|
|1856.619995|10433.870117| 16322.05957|14695.030273|  22064.529297|6614.600098|  9586.19043|5375.799805|
|1140.199951| 7280.069824|10787.049805| 9368.349609|  22357.169922|5547.600098|  6228.02002|4635.899902|
|2106.959961|11143.450195|18037.269531|20132.900391|  27932.849609|7027.200195|11866.370117|5811.799805|
|1303.890015| 8152.209961|12301.549805| 10046.19043|  22540.689453|5855.600098| 7251.680176|4611.600098|
|1361.209961| 8114.419922| 12964.69043| 9462.019531|  21477.720703|5927.200195| 6907.180176|4367.200195|
| 1724.52002| 9886.879883| 15675.94043|14504.360352|  23116.449219|6557.799805|  8635.05957|5229.399902|
|1307.869995| 8190.129883|12436.120117| 9935.120117|  21939.199219|     5846.0| 7213.740234|4560.299805|
|1984.540039|10910.389648|16986.509766|15947.290039|  24594.320312|     6806.0| 9650.129883|5531.299805|
|1123.829956| 7140.509766|10661.419922|        NULL|          NULL|5546.100098| 6183.709961|     4679.0|
|1224.849976| 7799.660156|11443.080078| 9624.990234|  24875.820312|5874.399902| 6753.200195|4871.899902|
|1641.810059|      9357.0|15237.589844|13513.200195|  21614.089844|     6399.5|  8306.69043|       NULL|
|1651.349976|  9420.55957|15001.990234|13395.379883|  21969.289062|     6452.5| 8299.030273|5067.799805|
|2091.830078|10978.330078|17848.460938|20459.900391|  27259.160156|6803.600098|11196.150391|     5505.5|
| 1861.76001|10122.730469|16116.240234|14737.379883|  22899.939453|6194.899902| 8581.900391|5243.299805|
|1198.380005| 7418.069824|11443.610352| 9298.879883|  20945.140625|     5246.0| 6235.160156|4168.700195|
|1316.819946| 7533.330078|12453.830078| 8579.389648|  18712.410156|     5350.5| 6338.939941|4080.199951|
|2125.060059| 11196.69043|18231.019531|20263.410156|  27991.830078|7030.700195|11814.009766|5667.200195|
|1650.810059| 9398.629883|15317.230469|13006.280273|  21224.880859|6373.200195| 8228.509766|4793.600098|
+-----------+------------+------------+------------+--------------+-----------+------------+-----------+
only showing top 20 rows

24/09/13 04:54:16 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/09/13 04:54:16 INFO SparkUI: Stopped Spark web UI at http://hpkf18-9f27ba91e9baae1d-driver-svc.harshal-f34d94fc.svc:4040
24/09/13 04:54:16 INFO KubernetesClusterSchedulerBackend: Shutting down all executors
24/09/13 04:54:16 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Asking each executor to shut down
24/09/13 04:54:16 WARN ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed.
24/09/13 04:54:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/09/13 04:54:16 INFO MemoryStore: MemoryStore cleared
24/09/13 04:54:16 INFO BlockManager: BlockManager stopped
24/09/13 04:54:16 INFO BlockManagerMaster: BlockManagerMaster stopped
24/09/13 04:54:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/09/13 04:54:16 INFO SparkContext: Successfully stopped SparkContext
24/09/13 04:54:16 INFO ShutdownHookManager: Shutdown hook called
24/09/13 04:54:16 INFO ShutdownHookManager: Deleting directory /var/data/spark-8a34b8fd-24a3-4fc0-9d7a-68e747f7104d/spark-69b8226d-1e8a-4d36-af0e-f5fc00fbc0c3
24/09/13 04:54:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-1b8d9475-e6cb-4e0e-9a2e-b27bbefec35c
24/09/13 04:54:16 INFO ShutdownHookManager: Deleting directory /var/data/spark-8a34b8fd-24a3-4fc0-9d7a-68e747f7104d/spark-69b8226d-1e8a-4d36-af0e-f5fc00fbc0c3/pyspark-74cc1036-57c0-40b8-980a-4a83df15b3a7
24/09/13 04:54:16 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
24/09/13 04:54:16 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
24/09/13 04:54:16 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
