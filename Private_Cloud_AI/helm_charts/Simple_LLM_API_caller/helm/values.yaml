# Default values for llm-client-app.
# This is a YAML-formatted file.

replicaCount: 1

image:
  repository: hspatil/llm-caller      #provide repo/image
  pullPolicy: IfNotPresent
  # Overwrite with the specific tag for your Docker image
  tag: "0.1.0" 

service:
  type: ClusterIP
  port: 7860
  targetPort: 7860     #container port

# # Optional configuration for ingress
# ingress:
#   enabled: false
#   annotations: {}
#   hosts:
#     - host: chart-example.local
#       paths:
#         - path: /
#           pathType: ImplementationSpecific
#   tls: []

# pod resources - this pod does not need GPUs 
resources:
  limits:
    cpu: 1000m
    memory: 1Gi
    #nvidia.com/gpu: 0
  requests:
    cpu: 500m
    memory: 512Mi
    #nvidia.com/gpu: 0

# ADDED FOR EZUA
# virtual service 
ezua:
  domainName: "${DOMAIN_NAME}"
  #Use next options in order to configure the application endpoint.
  #Example of a VirtualService is here:
  virtualService:
    endpoint: "simple-llm-caller.${DOMAIN_NAME}" # URL exposed - change for different subdomain
    istioGateway: "istio-system/ezaf-gateway"